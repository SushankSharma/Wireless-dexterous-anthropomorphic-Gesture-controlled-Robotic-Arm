# ğŸ¤– The Future of Robotic Arms is Here!

## Introduction ğŸ¤–
This project is all about redefining the interaction between human gestures and the digital world. ğŸ¤ Our goal is to create a **wireless-dexterous-anthropomorphic-gesture-controlled-robotic-arm** that mimics human hand gestures and performs various tasks in real-time. ğŸ¤–

## How it works ğŸ¤”
1. The Tx and Rx circuit attempt to connect via the **NRF24L01** transceiver module.
2. After a successful connection, the user can transmit hand gestures using a glove.
3. The transmitted gestures control the movement of the robotic arm.
4. The hardware interacts with the system and external environment using an **Arduino Nano** microcontroller.

## Requirements ğŸ’»
- Arduino Nano
- NRF24L01 Transceiver Module
- 3D Printer
- STL Files
- Glove
- Flex Sensors (*10)
- MG996 Servo Motors

## Let's get started ğŸš€

>1. Clone the repository
```
git clone https://github.com/[username]/[repository].git
```
>2. Assemble the hardware components as per the circuit diagram provided in the repository.
>3. Upload the code to the Arduino Nano Microcontroller.
>4. Put on the glove and control the movement of the robotic arm using hand gestures.

## Design Credits ğŸ¨
_**Inmoov**_

## Conclusion ğŸ¤©
This project shows that nearly **"96%"** of the transmitted signals are successfully configured and demonstrates the interaction between simple human gestures and the digital world. ğŸ¤ This study opens up avenues for further research in the area of gesture control and human-robot interaction. ğŸ¤– Say goodbye to boring button controls and hello to a fun, interactive, and intuitive way to control robots! ğŸš€
